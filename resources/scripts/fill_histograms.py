from icecube import icetray, dataclasses, dataio
from I3Tray import I3Tray

import sys
infiles = sys.argv[1:-1]
outfile = sys.argv[-1]

tray = I3Tray()

tray.AddModule('I3Reader', 'reader', filenamelist=infiles)

import numpy
from icecube.icetray import I3Units
class HoerandelWeight(object):
	gamma = numpy.array([2.71, 2.64, 2.54, 2.75, 2.95, 2.66, 2.72, 2.68, 2.69, 2.64, 2.66, 2.64, 2.66, 2.75, 2.69, 2.55, 2.68, 2.64, 2.65, 2.7, 2.64, 2.61, 2.63, 2.67, 2.46, 2.59])
	flux = numpy.array([0.0873, 0.0571, 0.00208, 0.000474, 0.000895, 0.0106, 0.00235, 0.0157, 0.000328, 0.0046, 0.000754, 0.00801, 0.00115, 0.00796, 0.00027, 0.00229, 0.000294, 0.000836, 0.000536, 0.00147, 0.000304, 0.00113, 0.000631, 0.00136, 0.00135, 0.0204])
	flux *= (I3Units.TeV/I3Units.GeV)**(gamma-1) # unit conversion
	def __init__(self, emin, emax, eslope, z=1, nevents=1e6*1):
		self.nevents = nevents
		self.emin = emin
		self.emax = emax
		self.eslope = eslope
		self.z = z
		if self.eslope < -1:
			g = self.eslope+1
			self.gen_norm = (self.emax**g - self.emin**g)/g
		else:
			self.gen_norm = numpy.log(self.emax/self.emin)
		self.norm = self.flux[int(z)-1]/self.nevents#/self.fluxsum(self.emin, self.emax, z, self.gamma[int(z)-1])
		
	def generation_probability(self, E):
		return E**(self.eslope)/self.gen_norm
	
	def fluxdiff(self, e, z, gamma, delta_gamma=2.1, eps_cutoff=1.9, E_knee=4.49*I3Units.PeV):
		"""
		Differential (unnormalized) Hoerandel flux
		"""
		return e**(-gamma)*(1+(e/(E_knee*z))**eps_cutoff)**(-delta_gamma/eps_cutoff)
	
	def fluxsum(self, emin, emax, z, gamma, delta_gamma=2.1, eps_cutoff=1.9, E_knee=4.49*I3Units.PeV):
		"""
		Integral Hoerandel flux
		"""
		# the Gauss hypergeometric function. whee!
		from scipy.special import hyp2f1
		antideriv = lambda e: ((e**(1-gamma))/(1-gamma))*hyp2f1(delta_gamma/eps_cutoff, (1-gamma)/eps_cutoff, (1-gamma)/eps_cutoff+1, -(e/(E_knee*z))**eps_cutoff)
		return antideriv(emax) - antideriv(emin)
		
	def __call__(self, E):
		#return 1/(self.nevents*self.generation_probability(E))
		return self.norm*self.fluxdiff(E, self.z, self.gamma[int(self.z)-1])/self.generation_probability(E)

import dashi, numpy, tables
from icecube import MuonGun
class Filla(icetray.I3Module):
	def __init__(self, ctx):
		icetray.I3Module.__init__(self, ctx)
		self.AddOutBox("OutBox")
	
	def Configure(self):
		from collections import defaultdict
		
		multbins = numpy.arange(1, 5)
		zenbins = numpy.arccos(numpy.linspace(1, 0, 11))
		def make_multi():
			return dashi.histogram.hist2d((zenbins, numpy.arange(1, 100)))
		def make_radius():
			return dashi.histogram.histogram(3, (zenbins, multbins, numpy.linspace(0, 50, 21)))
		def make_energy():
			return dashi.histogram.histogram(3, (zenbins, multbins, numpy.logspace(0, 6, 101)))
		
		self.primary = dashi.histogram.hist2d((zenbins, numpy.logspace(2, 11, 101)))
		self.multiplicity = defaultdict(make_multi)
		self.radius = defaultdict(make_radius)
		self.energy = defaultdict(make_energy)
		
		self.weighter = None
		
		import os
		if os.path.exists(outfile):
			os.unlink(outfile)
			
		self.nevents = 0
		
	def DAQ(self, frame):
		primary = frame['MCPrimary']
		#if primary.type != primary.PPlus:
		#	return
		# print primary
		if self.weighter is None:
			if 'CorsikaWeightDict' in frame:
				# generated by I3CORSIKAReader
				wm = frame['CorsikaWeightDict']
				z = max(int(primary.type)/100, 1)
				self.weighter = HoerandelWeight(wm['EnergyPrimaryMin'], wm['EnergyPrimaryMax'], wm['PrimarySpectralIndex'], z, wm['NEvents'])
			elif 'CorsikaWeightMap' in frame:
				# generated by I3CORSIKAWeightModule
				wm = frame['CorsikaWeightMap']
				if wm['Weight'] != 1.0:
					raise ValueError("Can't deal with weighted DCorsika")
				timescale = wm['TimeScale']
				area = wm['AreaSum']
				self.weighter = lambda energy: 1/(timescale*area)
		weight = self.weighter(primary.energy)
		#print weight
		#return
		
		zenith = numpy.asarray([primary.dir.zenith])
		
		self.primary.fill((numpy.asarray([zenith]), numpy.asarray([primary.energy])), weights=numpy.asarray([weight]))
		
		for depth, tracks in frame['Tracks']:
			energy = numpy.asarray([p.energy for p in tracks])
			radius = numpy.asarray([p.radius for p in tracks])
			zen = zenith.repeat(len(tracks))
			multiplicity = numpy.asarray([len(tracks)]).repeat(len(tracks))
			self.multiplicity[depth].fill((numpy.asarray([zenith]), numpy.asarray([len(energy)])), weights=numpy.asarray([weight]))
			w = (weight/len(tracks))*numpy.ones(len(tracks))
			self.radius[depth].fill((zen, multiplicity, radius), weights=w)
			self.energy[depth].fill((zen, multiplicity, energy), weights=w)
		
		self.nevents += 1
		if self.nevents % 100 == 0:
			print '%d events' % self.nevents
		
		self.PushFrame(frame)
		
	def Finish(self):
		
		with tables.openFile(outfile, 'w') as hdf:
			dashi.histsave(self.primary, hdf, '/', 'primary')
			for depth in self.multiplicity:
				path = '/%d' % depth
				group = hdf.createGroup('/', path[1:])
				dashi.histsave(self.multiplicity[depth], hdf, path, 'multiplicity')
				dashi.histsave(self.radius[depth], hdf, path, 'radius')
				dashi.histsave(self.energy[depth], hdf, path, 'energy')
		
tray.AddModule(Filla, 'filla')

# tray.AddModule('I3Writer', 'writer',
#     Streams=[icetray.I3Frame.DAQ, icetray.I3Frame.Physics],
#     DropOrphanStreams=[icetray.I3Frame.DAQ],
#     filename=outfile)

tray.AddModule('TrashCan', 'YesWeCan')
tray.Execute()
tray.Finish()
